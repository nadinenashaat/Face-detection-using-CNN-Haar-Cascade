{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "_iy9sPaOIXDg"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Define the paths to the training and testing datasets\n",
        "train_path = 'C:/Users/joann/Desktop/haarcascade/train'\n",
        "test_path = 'C:/Users/joann/Desktop/haarcascade/img'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms"
      ],
      "metadata": {
        "id": "U2iU1JdIL2Cc"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eICiWOU4IXDk"
      },
      "outputs": [],
      "source": [
        "def haar_cascade(image,face_cascade, name, i):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    # Detect faces in the image\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(500, 500))\n",
        "    return faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsK50eazIXDl",
        "outputId": "1fb8506c-0806-42b7-a6ec-558c62c224e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# Set the path of the main folder containing subfolders of images\n",
        "main_folder = 'C:/Users/joann/Desktop/haarcascade/train'\n",
        "\n",
        "# Load the Haar Cascade classifier for face detection\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Set the path of the folder to save the cropped face images\n",
        "save_folder = glob.glob('C:/Users/joann/Desktop/haarcascade/train/*')\n",
        "\n",
        "\n",
        "name_dic=[]\n",
        "for dir in save_folder:\n",
        "  print(dir)\n",
        "  dir = dir[40:]\n",
        "  # print(dir)\n",
        "  name_dic.append(dir)\n",
        "  \n",
        "print(name_dic)\n",
        "for name in name_dic:\n",
        "    imgs_dir=glob.glob('C:/Users/joann/Desktop/haarcascade/train/'+ name + '/*' )\n",
        "    i=0\n",
        "    for img_dir in imgs_dir:\n",
        "      \n",
        "      if img_dir.endswith('.jpg') or img_dir.endswith('.png') :\n",
        "            image=cv2.imread(img_dir)\n",
        "            \n",
        "            faces= haar_cascade(image,face_cascade, name, i)\n",
        "            \n",
        "            for (x, y, w, h) in faces:\n",
        "                    # Draw a rectangle around the detected face\n",
        "                    rectangle = cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "                    cv2.imwrite('C:/Users/joann/Desktop/haarcascade/squared_test/' + name + '/' + name + str(i) + '.png', rectangle)\n",
        "                    # Crop the image to only contain the detected face region\n",
        "                    face = image[y:y+h, x:x+w]\n",
        "                    # Resize the face to a fixed size for consistency\n",
        "                    face = cv2.resize(face, (500, 500))\n",
        "                    # Save the cropped face image to the save folder\n",
        "                    cv2.imwrite('C:/Users/joann/Desktop/haarcascade/cropped_test/' + name + '/' + name + str(i) + '.png', face)\n",
        "                    i=i+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "qKVytzubIXDr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "fe-A3ABkIXDs"
      },
      "outputs": [],
      "source": [
        "class FaceCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FaceCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        #self.fc1 = nn.Sigmoid()\n",
        "        self.fc1 = nn.Linear(65536, 2304)\n",
        "        \n",
        "        self.fc2 = nn.Linear(2304, 200)\n",
        "        #self.fc2 = nn.Linear(2304, 128)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        #self.fc2 = nn.Linear(128,6)\n",
        "        \n",
        "        self.fc3 = nn.Linear(200, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "       \n",
        "        x = self.fc3(x)\n",
        "        x = F.sigmoid(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Fvvwj-XQIXDt"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the data transformers\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    # transforms.CenterCrop((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "zBC5aOvsIXDu"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = FaceCNN()\n",
        "\n",
        "# Define the loss function and optimizer \n",
        "# The loss function measures the difference between the predicted output of the model and the actual output (the ground truth) for a given input.\n",
        "#The goal is to minimize this difference, or loss, during training, so that the model learns to make more accurate predictions.\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCFssleSPWH4",
        "outputId": "de6fef0d-3970-4aa5-89ba-fabd290153d6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "-a1C4TwoIXDu"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "train_dataset = ImageFolder('/content/drive/MyDrive/image_m3/cropped_new/', transform=data_transforms)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "# The validation set is used to evaluate the model's performance on unseen data, and prevent overfitting.\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Define the data loaders\n",
        "batch_size = 25\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "SpbMIYiPIXDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dbe5a1b-fc2b-4330-bee4-a6e4f3a130f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.6164\n",
            "Epoch [2/10], Loss: 0.5519\n",
            "Epoch [3/10], Loss: 0.5841\n",
            "Epoch [4/10], Loss: 0.6429\n",
            "Epoch [5/10], Loss: 0.5840\n",
            "Epoch [6/10], Loss: 0.6426\n",
            "Epoch [7/10], Loss: 0.7337\n",
            "Epoch [8/10], Loss: 0.7071\n",
            "Epoch [9/10], Loss: 0.5838\n",
            "Epoch [10/10], Loss: 0.7014\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set the device to run the model on (CPU or GPU)\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Define the number of epochs to train for\n",
        "\n",
        "\n",
        "# Train the model\n",
        "# Set the number of epochs to train for\n",
        "num_epochs = 10\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "# Define the dataset and dataloader\n",
        "train_dataset = ImageFolder('/content/drive/MyDrive/image_m3/cropped_new', transform=data_transforms)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=25, shuffle=True)\n",
        "\n",
        "# test_dataset = ImageFolder('/content/drive/MyDrive/image_m3/test', transform=data_transforms)\n",
        "# test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
        "\n",
        "\n",
        "#Train the model for the specified number of epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # Loop through the dataloader and train the model on each batch of images\n",
        "    for images, labels in train_dataloader:\n",
        "        # Clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "       \n",
        "       #e: Compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(images)\n",
        "        \n",
        "        # Compute the loss\n",
        "        new_label = F.one_hot(labels, num_classes=3) \n",
        "        loss = criterion(outputs, new_label.type(torch.FloatTensor) )\n",
        "\n",
        "        # Backward pass: Compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "1MFRsNOYIXDw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0cafb2-8a43-4d85-81dc-cfdb6ad63b0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train - Epoch: 10/10, Loss: 0.4963, Accuracy: 0.7143\n",
            "Validation - Epoch: 10/10, Loss: 0.7233420014381409, Accuracy: 0.8889\n"
          ]
        }
      ],
      "source": [
        "# Initialize the running loss and accuracy\n",
        "running_loss = 0.0\n",
        "running_corrects = 0\n",
        "\n",
        "# Loop over the training batches\n",
        "for inputs, labels in train_loader:\n",
        "    # Move the inputs and labels to the device\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    # Update the running loss and accuracy\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "# Calculate the average loss and accuracy for the epoch\n",
        "epoch_loss = running_loss / len(train_dataset)\n",
        "epoch_acc = running_corrects.double() / len(train_dataset)\n",
        "\n",
        "# Print the epoch statistics\n",
        "print(f'Train - Epoch: {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize the running loss and accuracy for the validation set\n",
        "running_loss = 0.0\n",
        "running_corrects = 0\n",
        "\n",
        "# Loop over the validation batches\n",
        "for inputs, labels in val_loader:\n",
        "    # Move the inputs and labels to the device\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    \n",
        "    # Update the running loss and accuracy\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    running_loss += loss.item() * inputs.size(0)\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "# Calculate the average loss and accuracy for the validation set\n",
        "epoch_loss = running_loss / len(val_dataset)\n",
        "epoch_acc = running_corrects.double() / len(val_dataset)\n",
        "\n",
        "# Print the validation statistics\n",
        "print(f'Validation - Epoch: {epoch+1}/{num_epochs}, Loss: {epoch_loss}, Accuracy: {epoch_acc:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***after many many trials, we have concluded that batch size = 25, number of epochs = 10, and model learning rate = 0.0001 has produced the highest accuracy in both train and validation***\n",
        "initial results were: Train - Epoch: 10/10, Loss: 0.9151, Accuracy: 0.6364 \n",
        "Validation - Epoch: 10/10, Loss: 1.218111515045166, Accuracy: 0.3333 "
      ],
      "metadata": {
        "id": "NzEJv_-InI-o"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}