{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import glob\n",
    "import os\n",
    "# Define the paths to the training and testing datasets\n",
    "# train_path = '/Users/dareengamal/Desktop/imageproc/Test'\n",
    "# test_path = '/Users/dareengamal/Desktop/imageproc/Train'\n",
    "train_path = 'D:/Giu/Image Processing and Computer Vision/haarcascade/Test'\n",
    "test_path = 'D:/Giu/Image Processing and Computer Vision/haarcascade/Train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def haar_cascade(image,face_cascade, name, i):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Detect faces in the image\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(500, 500))\n",
    " \n",
    "    \n",
    "    return faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chandler', 'Monica', 'Rachel']\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (11).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (12).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (13).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (14).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (15).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (16).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (17).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (18).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (19).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (2).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (20).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (21).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (22).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (23).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (24).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (25).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (26).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (27).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (28).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (29).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (3).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (30).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (31).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (32).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (33).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (34).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (35).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (36).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (37).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (38).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (39).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (4).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (40).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (41).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (42).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (43).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (44).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (45).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (46).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (47).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (48).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (49).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (5).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (50).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (6).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (7).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (8).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\chandler (9).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\Chandler_51.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\Chandler_52.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Chandler\\Chandler_53.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (1).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (10).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (11).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (12).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (13).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (14).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (15).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (16).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (17).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (18).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (19).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (2).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (20).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (21).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (22).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (24).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (25).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (26).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (27).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (28).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (29).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (3).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (30).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (31).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (32).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (33).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (34).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (35).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (36).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (37).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (38).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (39).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (4).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (40).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (41).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (42).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (43).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (44).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (45).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (46).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (47).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (48).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (49).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (5).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (50).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (6).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (7).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (8).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\monica (9).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_50.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_51.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_52.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_53.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_54.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_55.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_56.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_57.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Monica\\Monica_58.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (1).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (10).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (11).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (12).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (13).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (14).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (15).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (16).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (17).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (18).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (19).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (2).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (20).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (21).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (22).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (23).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (24).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (25).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (26).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (27).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (28).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (29).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (3).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (30).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (31).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (32).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (33).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (34).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (35).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (36).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (37).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (38).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (39).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (4).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (40).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (41).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (42).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (43).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (44).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (45).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (46).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (47).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (48).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (49).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (5).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (50).png\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (6).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (7).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (8).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\rachel (9).jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_51.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_52.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_53.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_54.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_55.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_56.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_57.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_58.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_59.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_60.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_61.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_62.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_63.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_64.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_65.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_66.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_67.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_68.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_69.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_70.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_71.jpg\n",
      "C:/Users/Dell/Desktop/haarcascade/train/Rachel\\Rachel_72.jpg\n"
     ]
    }
   ],
   "source": [
    "# hwa da\n",
    "\n",
    "# Set the path of the main folder containing subfolders of images\n",
    "main_folder = 'C:/Users/Dell/Desktop/haarcascade/Train'\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Set the path of the folder to save the cropped face images\n",
    "save_folder = glob.glob('C:/Users/Dell/Desktop/haarcascade/train/*')\n",
    "\n",
    "name_dic=[]\n",
    "for dir in save_folder:\n",
    "    dir = dir[40:]\n",
    "    name_dic.append(dir)\n",
    "\n",
    "print(name_dic)\n",
    "for name in name_dic:\n",
    "\n",
    "    imgs_dir=glob.glob('C:/Users/Dell/Desktop/haarcascade/train/'+ name + '/*' )\n",
    "    \n",
    "   \n",
    "    i=0\n",
    "    for img_dir in imgs_dir:\n",
    "      \n",
    "        if img_dir.endswith('.jpg') or img_dir.endswith('.png') :\n",
    "            image=cv2.imread(img_dir)\n",
    "            \n",
    "            faces= haar_cascade(image,face_cascade, name, i)\n",
    "            \n",
    "            for (x, y, w, h) in faces:\n",
    "                    # Draw a rectangle around the detected face\n",
    "                    \n",
    "                    rectangle = cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                    cv2.imwrite('C:/Users/Dell/Desktop/haarcascade/squared_faces/' + name + '/' + name + str(i) + '.png', rectangle)\n",
    "                    # Crop the image to only contain the detected face region\n",
    "                    face = image[y:y+h, x:x+w]\n",
    "                    # Resize the face to a fixed size for consistency\n",
    "                    face = cv2.resize(face, (500, 500))\n",
    "                    # Save the cropped face image to the save folder\n",
    "                    cv2.imwrite('C:/Users/Dell/Desktop/haarcascade/copped_new/' + name + '/' + name + str(i) + '.png', face)\n",
    "                    i=i+1\n",
    "               \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hwa da\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Set the path of the main folder containing subfolders of images\n",
    "main_folder = 'D:/Giu/Image Processing and Computer Vision/haarcascade/Train'\n",
    "\n",
    "# Load the Haar Cascade classifier for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Set the path of the folder to save the cropped face images\n",
    "save_folder = 'D:/Giu/Image Processing and Computer Vision/haarcascade/Cropped'\n",
    "\n",
    "# Loop through all the subfolders and images within the main folder\n",
    "for root, dirs, files in os.walk(main_folder):\n",
    "    for file in files:\n",
    "        # Check if the file is an image file\n",
    "        if file.endswith('.jpg') or file.endswith('.png'):\n",
    "            # Get the label from the subfolder name\n",
    "            label = os.path.basename(root)\n",
    "            # Read the image and convert it to grayscale\n",
    "            image = cv2.imread(os.path.join(root, file))\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Detect faces in the image\n",
    "            faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(500, 500))\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Draw a rectangle around the detected face\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                # Crop the image to only contain the detected face region\n",
    "                face = image[y:y+h, x:x+w]\n",
    "                # Resize the face to a fixed size for consistency\n",
    "                face = cv2.resize(face, (500, 500))\n",
    "                # Save the cropped face image to the save folder\n",
    "                filename = f\"{label}_{len(os.listdir(save_folder))+1}.jpg\"\n",
    "                cv2.imwrite(os.path.join(save_folder, filename), face)\n",
    "                # Display the original image and the cropped face region\n",
    "                cv2.imshow('Original Image', image)\n",
    "                cv2.imshow('Cropped Face', face)\n",
    "                cv2.waitKey(0)\n",
    "\n",
    "# Close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cropped=\"D:/Giu/Image Processing and Computer Vision/haarcascade/Cropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model updated el  size  --- x = torch.flatten(x, 1)\n",
    "\n",
    "#65536\n",
    "class FaceCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceCNN, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        #self.fc1 = nn.Sigmoid()\n",
    "        self.fc1 = nn.Linear(65536, 2304)\n",
    "        \n",
    "        self.fc2 = nn.Linear(2304, 200)\n",
    "        #self.fc2 = nn.Linear(2304, 128)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        #self.fc2 = nn.Linear(128,6)\n",
    "        \n",
    "        self.fc3 = nn.Linear(200, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "       \n",
    "        x = self.fc3(x)\n",
    "        x = F.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the data transformers\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    # transforms.CenterCrop((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the model\n",
    "model = FaceCNN()\n",
    "\n",
    "# Define the loss function and optimizer \n",
    "# The loss function measures the difference between the predicted output of the model and the actual output (the ground truth) for a given input.\n",
    "#The goal is to minimize this difference, or loss, during training, so that the model learns to make more accurate predictions.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_dataset = ImageFolder('C:/Users/Dell/Desktop/haarcascade/copped_new', transform=data_transforms)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "# The validation set is used to evaluate the model's performance on unseen data, and prevent overfitting.\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Define the data loaders\n",
    "batch_size = 15\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.5514\n",
      "Epoch [2/10], Loss: 1.0514\n",
      "Epoch [3/10], Loss: 1.0514\n",
      "Epoch [4/10], Loss: 1.0514\n",
      "Epoch [5/10], Loss: 1.5514\n",
      "Epoch [6/10], Loss: 0.5514\n",
      "Epoch [7/10], Loss: 1.0514\n",
      "Epoch [8/10], Loss: 0.5514\n",
      "Epoch [9/10], Loss: 0.5514\n",
      "Epoch [10/10], Loss: 1.0514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the device to run the model on (CPU or GPU)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define the number of epochs to train for\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# Set the number of epochs to train for\n",
    "num_epochs = 10\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Define the dataset and dataloader\n",
    "train_dataset = ImageFolder('C:/Users/Dell/Desktop/haarcascade/copped_new', transform=data_transforms)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "#Train the model for the specified number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # Loop through the dataloader and train the model on each batch of images\n",
    "    for images, labels in train_dataloader:\n",
    "        # Clear the gradients\n",
    "        optimizer.zero_grad()\n",
    "       \n",
    "       #e: Compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute the loss\n",
    "        new_label = F.one_hot(labels, num_classes=3) \n",
    "        loss = criterion(outputs, new_label.type(torch.FloatTensor) )\n",
    "\n",
    "        # Backward pass: Compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the model parameters\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Epoch: 10/10, Loss: 0.9151, Accuracy: 0.6364\n",
      "Validation - Epoch: 10/10, Loss: 1.218111515045166, Accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# Initialize the running loss and accuracy\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "\n",
    "# Loop over the training batches\n",
    "for inputs, labels in train_loader:\n",
    "    # Move the inputs and labels to the device\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update the running loss and accuracy\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# Calculate the average loss and accuracy for the epoch\n",
    "epoch_loss = running_loss / len(train_dataset)\n",
    "epoch_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "# Print the epoch statistics\n",
    "print(f'Train - Epoch: {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize the running loss and accuracy for the validation set\n",
    "running_loss = 0.0\n",
    "running_corrects = 0\n",
    "\n",
    "# Loop over the validation batches\n",
    "for inputs, labels in val_loader:\n",
    "    # Move the inputs and labels to the device\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Update the running loss and accuracy\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "# Calculate the average loss and accuracy for the validation set\n",
    "epoch_loss = running_loss / len(val_dataset)\n",
    "epoch_acc = running_corrects.double() / len(val_dataset)\n",
    "\n",
    "# Print the validation statistics\n",
    "print(f'Validation - Epoch: {epoch+1}/{num_epochs}, Loss: {epoch_loss}, Accuracy: {epoch_acc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
